{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6ab0822a9f444638848aa488cd3ad352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30e26fe6b6b1427e9991471dc87f7960",
              "IPY_MODEL_a3472274176d4f1d950655af675b1cbb",
              "IPY_MODEL_926036c56459490cb70e177eb9c1cff2"
            ],
            "layout": "IPY_MODEL_3098b303f3bd4192b183643839790f37"
          }
        },
        "30e26fe6b6b1427e9991471dc87f7960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5518b026082d4df7b5e8f15c43c7c5d2",
            "placeholder": "​",
            "style": "IPY_MODEL_6cd63160f12d4d49962e355eefd1bcf5",
            "value": "Epoch 4: 100%"
          }
        },
        "a3472274176d4f1d950655af675b1cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02d7b5c0c3424fc28ec9c9f4d774929b",
            "max": 60000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbf87081398b46389291495747733d54",
            "value": 60000
          }
        },
        "926036c56459490cb70e177eb9c1cff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_197134d490ab41d4971560ba740aa57b",
            "placeholder": "​",
            "style": "IPY_MODEL_3733fc0f44ce4d39907e2797b7375ac7",
            "value": " 60000/60000 [03:00&lt;00:00, 333.29it/s, v_num=0]"
          }
        },
        "3098b303f3bd4192b183643839790f37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "5518b026082d4df7b5e8f15c43c7c5d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cd63160f12d4d49962e355eefd1bcf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02d7b5c0c3424fc28ec9c9f4d774929b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbf87081398b46389291495747733d54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "197134d490ab41d4971560ba740aa57b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3733fc0f44ce4d39907e2797b7375ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Git and Github"
      ],
      "metadata": {
        "id": "WESVh0qFUEGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"Mustafa643\"\n",
        "!git config --global user.email \"ma5755333@gmail.com\"\n",
        "!git config --global user.password \"mustash643\""
      ],
      "metadata": {
        "id": "qdmixlC0UDRG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = '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'\n",
        "username = 'Mustafa643'\n",
        "repo = 'PyTorch_Lightning'"
      ],
      "metadata": {
        "id": "LaQi6XMjU3bD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://{token}@github.com/{username}/{repo}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B812p5HGW-DR",
        "outputId": "0558f22e-b4a5-4929-cc59-904f68d2debc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PyTorch_Lightning'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd {repo}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEpyb9zek8Mv",
        "outputId": "13b82eb9-cebc-482b-c16f-bca5c968cab1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PyTorch_Lightning/PyTorch_Lightning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPe2rhofljc5",
        "outputId": "7fab62b1-5c78-4d97-8581-7393829e1029"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv/content/sample_data/CAT2.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blXgA_ZvmXBr",
        "outputId": "a1ebfa9c-7843-42a5-8d89-a2b7943d207c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: mv/content/sample_data/CAT2.ipynb: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add --all"
      ],
      "metadata": {
        "id": "bMpXy-sElsaf"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -a -m \"Added PyTorch_Lightning\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnERw7vrl3Hw",
        "outputId": "9024726b-a3ee-4a4f-f9e8-d625136d0bc8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mkgw96hWmAkd",
        "outputId": "ccdc144e-2abb-4666-8fa3-19304d6b82a8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "origin\thttps://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@github.com/Mustafa643/PyTorch_Lightning (fetch)\n",
            "origin\thttps://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@github.com/Mustafa643/PyTorch_Lightning (push)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push master origin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-XHqczCozHX",
        "outputId": "2aaa03ca-cde5-4afc-f921-ca7daf9e1ac5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: 'master' does not appear to be a git repository\n",
            "fatal: Could not read from remote repository.\n",
            "\n",
            "Please make sure you have the correct access rights\n",
            "and the repository exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push -u origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-kNYYDumJNf",
        "outputId": "4258338e-187a-4279-9256-52aa6c22d3ac"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'main' set up to track remote branch 'main' from 'origin'.\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add imports\n",
        "\n"
      ],
      "metadata": {
        "id": "o-AbFPmEYgya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Install with pip\n"
      ],
      "metadata": {
        "id": "9Z1SoI_39GMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxRcUPNT9DIb",
        "outputId": "9378aecf-9391-4bc4-b664-1dc1a078dea9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightning\n",
            "  Using cached lightning-2.2.1-py3-none-any.whl (2.1 MB)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]<2025.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2023.6.0)\n",
            "Collecting lightning-utilities<2.0,>=0.8.0 (from lightning)\n",
            "  Using cached lightning_utilities-0.11.1-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.25.2)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (24.0)\n",
            "Requirement already satisfied: torch<4.0,>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.2.1+cu121)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n",
            "  Using cached torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.10.0)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Using cached pytorch_lightning-2.2.1-py3-none-any.whl (801 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (3.9.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.8.0->lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m704.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/nvidia-cublas-cu12/\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting nvidia-cublas-cu12==12.1.3.1 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<4.0,>=1.13.0->lightning)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<4.0,>=1.13.0->lightning) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=1.13.0->lightning) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning, lightning\n",
            "Successfully installed lightning-2.2.1 lightning-utilities-0.11.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 pytorch-lightning-2.2.1 torchmetrics-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "R8FUESeM9wEf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zdpwGEDs9vzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "i3GXa5qzSHhX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8b8e995-51b5-4307-c0ee-d5da709a014c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightning\n",
            "  Downloading lightning-2.2.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]<2025.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2023.6.0)\n",
            "Collecting lightning-utilities<2.0,>=0.8.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.11.1-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.25.2)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (24.0)\n",
            "Requirement already satisfied: torch<4.0,>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.2.1+cu121)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n",
            "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.10.0)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.2.1-py3-none-any.whl (801 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.6/801.6 kB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (3.9.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.8.0->lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch<4.0,>=1.13.0->lightning)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<4.0,>=1.13.0->lightning)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<4.0,>=1.13.0->lightning) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=1.13.0->lightning) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning, lightning\n",
            "Successfully installed lightning-2.2.1 lightning-utilities-0.11.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 pytorch-lightning-2.2.1 torchmetrics-1.3.2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "!pip install lightning\n",
        "from torch.utils.data import DataLoader\n",
        "import lightning as L"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the PyTorch nn.Modules"
      ],
      "metadata": {
        "id": "0kfa5gKmYkae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fe8tvIdoYpc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.l1(x)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.l1(x)"
      ],
      "metadata": {
        "id": "-AKb9_SrYeVR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define a LightningModule\n"
      ],
      "metadata": {
        "id": "fZthaQPPYwtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LitAutoEncoder(L.LightningModule):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # training_step defines the train loop.\n",
        "        x, y = batch\n",
        "        x = x.view(x.size(0), -1)\n",
        "        z = self.encoder(x)\n",
        "        x_hat = self.decoder(z)\n",
        "        loss = F.mse_loss(x_hat, x)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "        return optimizer"
      ],
      "metadata": {
        "id": "NtSZ6I3VYwLh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define the training dataset\n"
      ],
      "metadata": {
        "id": "XCAii58KsJRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())\n",
        "train_loader = DataLoader(dataset)"
      ],
      "metadata": {
        "id": "8PNWyo2hsJp3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bdf91fe-a55e-4595-aff8-c9c64f3c6107"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 109899687.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/MNIST/raw/train-images-idx3-ubyte.gz to /content/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 24457034.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/MNIST/raw/train-labels-idx1-ubyte.gz to /content/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 170948472.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 19281911.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model\n"
      ],
      "metadata": {
        "id": "3b_A7b2zsTQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "# model\n",
        "autoencoder = LitAutoEncoder(Encoder(), Decoder())\n",
        "\n",
        "# train model\n",
        "trainer = L.Trainer(max_epochs=5)\n",
        "trainer.fit(model=autoencoder, train_dataloaders=train_loader)\n",
        "\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "training_time = end_time - start_time\n",
        "print(f\"Training time for epochs: {training_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656,
          "referenced_widgets": [
            "6ab0822a9f444638848aa488cd3ad352",
            "30e26fe6b6b1427e9991471dc87f7960",
            "a3472274176d4f1d950655af675b1cbb",
            "926036c56459490cb70e177eb9c1cff2",
            "3098b303f3bd4192b183643839790f37",
            "5518b026082d4df7b5e8f15c43c7c5d2",
            "6cd63160f12d4d49962e355eefd1bcf5",
            "02d7b5c0c3424fc28ec9c9f4d774929b",
            "dbf87081398b46389291495747733d54",
            "197134d490ab41d4971560ba740aa57b",
            "3733fc0f44ce4d39907e2797b7375ac7"
          ]
        },
        "id": "jIo6HFDHsTy8",
        "outputId": "be2db5a3-8c94-4d25-a894-2a33f28cce46"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "WARNING: Missing logger folder: /content/lightning_logs\n",
            "WARNING:lightning.pytorch.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name    | Type    | Params\n",
            "------------------------------------\n",
            "0 | encoder | Encoder | 50.4 K\n",
            "1 | decoder | Decoder | 51.2 K\n",
            "------------------------------------\n",
            "101 K     Trainable params\n",
            "0         Non-trainable params\n",
            "101 K     Total params\n",
            "0.407     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name    | Type    | Params\n",
            "------------------------------------\n",
            "0 | encoder | Encoder | 50.4 K\n",
            "1 | decoder | Decoder | 51.2 K\n",
            "------------------------------------\n",
            "101 K     Trainable params\n",
            "0         Non-trainable params\n",
            "101 K     Total params\n",
            "0.407     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ab0822a9f444638848aa488cd3ad352"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: `Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time for epochs: 913.9188094139099 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eliminate the training loop\n"
      ],
      "metadata": {
        "id": "e3gaEozl2FeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = LitAutoEncoder(Encoder(), Decoder())\n",
        "optimizer = autoencoder.configure_optimizers()\n",
        "\n",
        "for batch_idx, batch in enumerate(train_loader):\n",
        "    loss = autoencoder.training_step(batch, batch_idx)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "cd52XlVu2GLS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find the train and test splits"
      ],
      "metadata": {
        "id": "Lu_avmk15LO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as data\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Load data sets\n",
        "transform = transforms.ToTensor()\n",
        "train_set = datasets.MNIST(root=\"MNIST\", download=True, train=True, transform=transform)\n",
        "test_set = datasets.MNIST(root=\"MNIST\", download=True, train=False, transform=transform)"
      ],
      "metadata": {
        "id": "4UiV8CUr5K_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7d3fc2a-41d0-4d2c-bbf2-d31be654c601"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 334269012.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST/MNIST/raw/train-images-idx3-ubyte.gz to MNIST/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 45919520.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 13827440.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7980950.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define the test loop\n"
      ],
      "metadata": {
        "id": "lz57QpJw5b8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LitAutoEncoder(L.LightningModule):\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        ...\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        # this is the test loop\n",
        "        x, y = batch\n",
        "        x = x.view(x.size(0), -1)\n",
        "        z = self.encoder(x)\n",
        "        x_hat = self.decoder(z)\n",
        "        test_loss = F.mse_loss(x_hat, x)\n",
        "        self.log(\"test_loss\", test_loss)\n",
        "class Trainer:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def test(self, model, dataloaders):\n",
        "        # Perform testing here\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "RtWs7nOI5bk8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train with the test loop"
      ],
      "metadata": {
        "id": "yJHTZdxD5lAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LitAutoEncoder(nn.Module):\n",
        "    def _init_(self, encoder, decoder):\n",
        "        super(LitAutoEncoder, self)._init_()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through the encoder\n",
        "        encoded = self.encoder(x)\n",
        "        # Forward pass through the decoder\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded"
      ],
      "metadata": {
        "id": "F_V8JwCZHipL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class Trainer:\n",
        "    def _init_(self, test_set):\n",
        "        self.test_set = test_set\n",
        "\n",
        "    def test(self, model, dataloaders):\n",
        "        # Assuming you have a method to perform testing on the model using dataloaders\n",
        "        pass\n",
        "\n",
        "trainer = Trainer(num_sanity_val_steps=2)\n",
        "# initialize the Trainer\n",
        "trainer = Trainer(test_set)\n",
        "\n",
        "# model\n",
        "#model = autoencoder()\n",
        "autoencoder = LitAutoEncoder(Encoder(), Decoder())\n",
        "\n",
        "# test the model\n",
        "trainer.test(autoencoder, DataLoader(test_set))"
      ],
      "metadata": {
        "id": "CWO4tRPp5kIB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(fast_dev_run=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "Q-vI2V9ASm0J",
        "outputId": "d9f43376-bd17-4aa0-bed3-b699781a13be"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Trainer() takes no arguments",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-b8c2a408fc90>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfast_dev_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: Trainer() takes no arguments"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add a validation loop\n",
        "Split the training data\n",
        "\n"
      ],
      "metadata": {
        "id": "HtGMeEreEuqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use 20% of training data for validation\n",
        "train_set_size = int(len(train_set) * 0.8)\n",
        "valid_set_size = len(train_set) - train_set_size\n",
        "\n",
        "# split the train set into two\n",
        "seed = torch.Generator().manual_seed(42)\n",
        "train_set, valid_set = data.random_split(train_set, [train_set_size, valid_set_size], generator=seed)"
      ],
      "metadata": {
        "id": "JMydWf7cEuJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the validation loop\n"
      ],
      "metadata": {
        "id": "f2N4uqk8E98i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LitAutoEncoder(L.LightningModule):\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        ...\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        # this is the validation loop\n",
        "        x, _ = batch\n",
        "        x = x.view(x.size(0), -1)\n",
        "        z = self.encoder(x)\n",
        "        x_hat = self.decoder(z)\n",
        "        val_loss = F.mse_loss(x_hat, x)\n",
        "        self.log(\"val_loss\", val_loss)"
      ],
      "metadata": {
        "id": "KXU-ezEdE-Tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train with the validation loop\n"
      ],
      "metadata": {
        "id": "jdhprbbkFDY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_set)\n",
        "valid_loader = DataLoader(valid_set)\n",
        "model = LitAutoEncoder(...)\n",
        "\n",
        "# train with both splits\n",
        "trainer = L.Trainer()\n",
        "trainer.fit(model, train_loader, valid_loader)"
      ],
      "metadata": {
        "id": "JhRieee9FCu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save a checkpoint\n"
      ],
      "metadata": {
        "id": "uVO83l9MGr08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# simply by using the Trainer you get automatic checkpointing\n",
        "trainer = Trainer()"
      ],
      "metadata": {
        "id": "WxH7jvgPGsBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LightningModule from checkpoint\n"
      ],
      "metadata": {
        "id": "c3KufJZ2G1hs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyLightningModule.load_from_checkpoint(\"/path/to/checkpoint.ckpt\")\n",
        "\n",
        "# disable randomness, dropout, etc...\n",
        "model.eval()\n",
        "\n",
        "# predict with the model\n",
        "y_hat = model(x)"
      ],
      "metadata": {
        "id": "3Bt0tK91G3mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save hyperparameters\n"
      ],
      "metadata": {
        "id": "-__OYSX8G5VN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLightningModule(LightningModule):\n",
        "    def __init__(self, learning_rate, another_parameter, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        checkpoint = torch.load(checkpoint, map_location=lambda storage, loc: storage)\n",
        "print(checkpoint[\"hyper_parameters\"])\n",
        "# {\"learning_rate\": the_value, \"another_parameter\": the_other_value}\n",
        "model = MyLightningModule.load_from_checkpoint(\"/path/to/checkpoint.ckpt\")\n",
        "print(model.learning_rate)"
      ],
      "metadata": {
        "id": "hJdwfvRMG7lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize with other parameters\n"
      ],
      "metadata": {
        "id": "YZ_v0IcuG9N5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if you train and save the model like this it will use these values when loading\n",
        "# the weights. But you can overwrite this\n",
        "LitModel(in_dim=32, out_dim=10)\n",
        "\n",
        "# uses in_dim=32, out_dim=10\n",
        "model = LitModel.load_from_checkpoint(PATH)\n",
        "\n",
        "# uses in_dim=128, out_dim=10\n",
        "model = LitModel.load_from_checkpoint(PATH, in_dim=128, out_dim=10)\n",
        "class LitAutoencoder(L.LightningModule):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        ...\n",
        "\n",
        "    ...\n",
        "\n",
        "\n",
        "model = LitAutoEncoder.load_from_checkpoint(PATH, encoder=encoder, decoder=decoder)"
      ],
      "metadata": {
        "id": "LDFvfEE4HDZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## nn.Module from checkpoint\n"
      ],
      "metadata": {
        "id": "wKWiHx0lHIBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(CKPT_PATH)\n",
        "print(checkpoint.keys())\n",
        "#example\n",
        "class Encoder(nn.Module):\n",
        "    ...\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    ...\n",
        "\n",
        "\n",
        "class Autoencoder(L.LightningModule):\n",
        "    def __init__(self, encoder, decoder, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "\n",
        "autoencoder = Autoencoder(Encoder(), Decoder())\n",
        "checkpoint = torch.load(CKPT_PATH)\n",
        "encoder_weights = {k: v for k, v in checkpoint[\"state_dict\"].items() if k.startswith(\"encoder.\")}\n",
        "decoder_weights = {k: v for k, v in checkpoint[\"state_dict\"].items() if k.startswith(\"decoder.\")}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "n7KQruLGHJkB",
        "outputId": "f1254bf9-ee0b-4826-acf3-cc06dea8ca71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a0fb32a46a67>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCKPT_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Disable checkpointing\n"
      ],
      "metadata": {
        "id": "mP7URWM9HTvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(enable_checkpointing=False)"
      ],
      "metadata": {
        "id": "6Xv7kX0rHWpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resume training state\n"
      ],
      "metadata": {
        "id": "_fFS--ZdHXSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LitModel()\n",
        "trainer = Trainer()\n",
        "\n",
        "# automatically restores model, epoch, step, LR schedulers, etc...\n",
        "trainer.fit(model, ckpt_path=\"some/path/to/my_checkpoint.ckpt\")"
      ],
      "metadata": {
        "id": "9d1K9FivHZYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EarlyStopping Callback\n"
      ],
      "metadata": {
        "id": "QUTo1sqaHfHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
        "\n",
        "\n",
        "class LitModel(LightningModule):\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss = ...\n",
        "        self.log(\"val_loss\", loss)\n",
        "\n",
        "\n",
        "model = LitModel()\n",
        "trainer = Trainer(callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\")])\n",
        "trainer.fit(model)\n",
        "early_stop_callback = EarlyStopping(monitor=\"val_accuracy\", min_delta=0.00, patience=3, verbose=False, mode=\"max\")\n",
        "trainer = Trainer(callbacks=[early_stop_callback])\n",
        "class MyEarlyStopping(EarlyStopping):\n",
        "    def on_validation_end(self, trainer, pl_module):\n",
        "        # override this to disable early stopping at the end of val loop\n",
        "        pass\n",
        "\n",
        "    def on_train_end(self, trainer, pl_module):\n",
        "        # instead, do it at the end of training loop\n",
        "        self._run_early_stopping_check(trainer)"
      ],
      "metadata": {
        "id": "N9Bjgk0gHgEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Use a pretrained LightningModule\n"
      ],
      "metadata": {
        "id": "B1vuq-54FWWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    ...\n",
        "\n",
        "\n",
        "class AutoEncoder(LightningModule):\n",
        "    def __init__(self):\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "\n",
        "class CIFAR10Classifier(LightningModule):\n",
        "    def __init__(self):\n",
        "        # init the pretrained LightningModule\n",
        "        self.feature_extractor = AutoEncoder.load_from_checkpoint(PATH)\n",
        "        self.feature_extractor.freeze()\n",
        "\n",
        "        # the autoencoder outputs a 100-dim representation and CIFAR-10 has 10 classes\n",
        "        self.classifier = nn.Linear(100, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        representations = self.feature_extractor(x)\n",
        "        x = self.classifier(representations)\n",
        "        ..."
      ],
      "metadata": {
        "id": "w_zPFwGDFWqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Example: Imagenet (Computer Vision)\n"
      ],
      "metadata": {
        "id": "dU7m8pckGBSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "class ImagenetTransferLearning(LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # init a pretrained resnet\n",
        "        backbone = models.resnet50(weights=\"DEFAULT\")\n",
        "        num_filters = backbone.fc.in_features\n",
        "        layers = list(backbone.children())[:-1]\n",
        "        self.feature_extractor = nn.Sequential(*layers)\n",
        "        self.feature_extractor.eval()\n",
        "\n",
        "        # use the pretrained model to classify cifar-10 (10 image classes)\n",
        "        num_target_classes = 10\n",
        "        self.classifier = nn.Linear(num_filters, num_target_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        with torch.no_grad():\n",
        "            representations = self.feature_extractor(x).flatten(1)\n",
        "        x = self.classifier(representations)\n",
        "        ..."
      ],
      "metadata": {
        "id": "q_xSK97zGByf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetune\n",
        "\n"
      ],
      "metadata": {
        "id": "5JUo_sBJGGia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ImagenetTransferLearning()\n",
        "trainer = Trainer()\n",
        "trainer.fit(model)"
      ],
      "metadata": {
        "id": "nhltexZxGG84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## And use it to predict your data of interest"
      ],
      "metadata": {
        "id": "UvZgfIPmGKUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ImagenetTransferLearning.load_from_checkpoint(PATH)\n",
        "model.freeze()\n",
        "\n",
        "x = some_images_from_cifar10()\n",
        "predictions = model(x)"
      ],
      "metadata": {
        "id": "S7VSFLuHGKlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example: BERT (NLP)\n"
      ],
      "metadata": {
        "id": "Fe5A2th6GQXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertMNLIFinetuner(LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-cased\", output_attentions=True)\n",
        "        self.W = nn.Linear(bert.config.hidden_size, 3)\n",
        "        self.num_classes = 3\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        h, _, attn = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "\n",
        "        h_cls = h[:, 0]\n",
        "        logits = self.W(h_cls)\n",
        "        return logits, attn"
      ],
      "metadata": {
        "id": "LwtZ0XnZGSKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ArgumentParser"
      ],
      "metadata": {
        "id": "87hghmEAGWvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from argparse import ArgumentParser\n",
        "\n",
        "parser = ArgumentParser()\n",
        "\n",
        "# Trainer arguments\n",
        "parser.add_argument(\"--devices\", type=int, default=2)\n",
        "\n",
        "# Hyperparameters for the model\n",
        "parser.add_argument(\"--layer_1_dim\", type=int, default=128)\n",
        "\n",
        "# Parse the user inputs and defaults (returns a argparse.Namespace)\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Use the parsed arguments in your program\n",
        "trainer = Trainer(devices=args.devices)\n",
        "model = MyModel(layer_1_dim=args.layer_1_dim)"
      ],
      "metadata": {
        "id": "avjvrSqMGVza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find training loop bottlenecks\n"
      ],
      "metadata": {
        "id": "EDkL4qjkHt9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(profiler=\"simple\")"
      ],
      "metadata": {
        "id": "ptG2ddLIRAZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Profile the time within every function\n"
      ],
      "metadata": {
        "id": "aIYHr4CpS07q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(profiler=\"advanced\")"
      ],
      "metadata": {
        "id": "6RRSYDdgS0ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning.pytorch.profilers import AdvancedProfiler\n",
        "\n",
        "profiler = AdvancedProfiler(dirpath=\".\", filename=\"perf_logs\")\n",
        "trainer = Trainer(profiler=profiler)"
      ],
      "metadata": {
        "id": "xARCqikuS5SX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Track metrics\n"
      ],
      "metadata": {
        "id": "Km2ZnbHCTAGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LitModel(L.LightningModule):\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        value = ...\n",
        "        self.log(\"some_value\", value)\n",
        "        values = {\"loss\": loss, \"acc\": acc, \"metric_n\": metric_n}  # add more items if needed\n",
        "self.log_dict(values)"
      ],
      "metadata": {
        "id": "Ho0N1IpMTA0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values = {\"loss\": loss, \"acc\": acc, \"metric_n\": metric_n}  # add more items if needed\n",
        "self.log_dict(values)"
      ],
      "metadata": {
        "id": "Cr5M3-EHTKkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard --logdir=lightning_logs/\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=lightning_logs/"
      ],
      "metadata": {
        "id": "pSjkeYc-TS3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation_step(self, batch, batch_idx):\n",
        "    value = batch_idx + 1\n",
        "    self.log(\"average_value\", value)"
      ],
      "metadata": {
        "id": "bfIgGUekTYfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyLightningModule.load_from_checkpoint(\"/path/to/checkpoint.ckpt\")\n",
        "\n",
        "# disable randomness, dropout, etc...\n",
        "model.eval()\n",
        "\n",
        "# predict with the model\n",
        "y_hat = model(x)"
      ],
      "metadata": {
        "id": "7ObaZk7aTdqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLightningModule(LightningModule):\n",
        "    def __init__(self, learning_rate, another_parameter, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()"
      ],
      "metadata": {
        "id": "-CRYE3wVTei9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(checkpoint, map_location=lambda storage, loc: storage)\n",
        "print(checkpoint[\"hyper_parameters\"])\n",
        "# {\"learning_rate\": the_value, \"another_parameter\": the_other_value}"
      ],
      "metadata": {
        "id": "DFD3YwXVTgS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyLightningModule.load_from_checkpoint(\"/path/to/checkpoint.ckpt\")\n",
        "print(model.learning_rate)"
      ],
      "metadata": {
        "id": "P_Ig-oBOTiJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if you train and save the model like this it will use these values when loading\n",
        "# the weights. But you can overwrite this\n",
        "LitModel(in_dim=32, out_dim=10)\n",
        "\n",
        "# uses in_dim=32, out_dim=10\n",
        "model = LitModel.load_from_checkpoint(PATH)\n",
        "\n",
        "# uses in_dim=128, out_dim=10\n",
        "model = LitModel.load_from_checkpoint(PATH, in_dim=128, out_dim=10)"
      ],
      "metadata": {
        "id": "vbdvXEdOTk2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LitAutoencoder(L.LightningModule):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        ...\n",
        "\n",
        "    ...\n",
        "\n",
        "\n",
        "model = LitAutoEncoder.load_from_checkpoint(PATH, encoder=encoder, decoder=decoder)"
      ],
      "metadata": {
        "id": "SXNK29UfTm7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(CKPT_PATH)\n",
        "print(checkpoint.keys())"
      ],
      "metadata": {
        "id": "vlBV8MGwTn0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    ...\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    ...\n",
        "\n",
        "\n",
        "class Autoencoder(L.LightningModule):\n",
        "    def __init__(self, encoder, decoder, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "\n",
        "autoencoder = Autoencoder(Encoder(), Decoder())"
      ],
      "metadata": {
        "id": "_hbjF2rcTqPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(CKPT_PATH)\n",
        "encoder_weights = {k: v for k, v in checkpoint[\"state_dict\"].items() if k.startswith(\"encoder.\")}\n",
        "decoder_weights = {k: v for k, v in checkpoint[\"state_dict\"].items() if k.startswith(\"decoder.\")}"
      ],
      "metadata": {
        "id": "v4wGEeNITpM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(enable_checkpointing=False)"
      ],
      "metadata": {
        "id": "eWJrJR-FTtxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LitModel()\n",
        "trainer = Trainer()\n",
        "\n",
        "# automatically restores model, epoch, step, LR schedulers, etc...\n",
        "trainer.fit(model, ckpt_path=\"some/path/to/my_checkpoint.ckpt\")"
      ],
      "metadata": {
        "id": "sI5UZZQETvHc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}